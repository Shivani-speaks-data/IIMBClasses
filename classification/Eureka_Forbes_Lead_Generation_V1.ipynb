{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPROVING LEAD GENERATION AT EUREKA FORBES \n",
    "\n",
    "Eureka Forbes, part of the conglomerate Shapoorji Pallonji Group, is currently one of the world's largest direct sales company known for its water purifier brand Aquaguard with a turnover of more than INR 30 billion. The company is estimated to have a customer base of 20 million across 53 countries. The company's distribution channel includes a direct sales force of dealers, institutional channels, business partner network and a rural channel across 1500 cities and towns in India. The company's previous customer acquisition model ensured that interested customers were individually visited for demonstration of the product and for completion of purchase. While this made the company a household name, it kept the acquisition costs on the higher side. With the imminence of online retailing, the brand had been taking steps to establish their digital presence and build a stable online sales channel. The company website (www.eurekaforbes.com) attracts online traffic from various sources such as organic searches, google ads, email campaigns, etc. The company has started to use this click stream data to build a rich database of visitor acquisition factors and behavioral variables such as session duration, device category, pages visited, lead forms filled, etc. using the Google Analytics Reporting API. The company identifies these visitors as potential customers and is actively deploying remarketing campaigns with optimism to convert them. \n",
    "\n",
    "**Source**: https://store.hbr.org/product/improving-lead-generation-at-eureka-forbes-using-machine-learning-algorithms/IMB779\n",
    "\n",
    "The business goal is clearly defined for the company â€“ they want to target potential customers while keeping\n",
    "the cost per lead (CPL) as low as possible. For Kashif Kudalkar, the Deputy General Manager for Digital\n",
    "Marketing and Analytics, the task is to achieve better conversion at lower costs. This is achievable when\n",
    "the target audience is narrowed down to a sizeable number for remarketing campaigns. Kashif wants to use\n",
    "the collected behavioral and visitor data to achieve the following objectives:\n",
    "\n",
    "1. Find the target audience with a high probability of submitting a lead and eventually converting.\n",
    "2. Segment the visitor audience into buckets based on their activity for designing better advertising and\n",
    "remarketing campaigns.\n",
    "3. Finally, have a probability score that can be used to run a personalized campaign for users/segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eureka_df_v3 = pd.read_csv('https://raw.githubusercontent.com/manaranjanp/IIMBClasses/main/classification/eureka_encoded_csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eureka_df_v3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eureka_df_v3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eureka_df_v3.converted.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eureka_df_v3.converted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = list(eureka_df_v3.columns)\n",
    "X_features.remove('converted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_0, test_set_0 = train_test_split(eureka_df_v3[eureka_df_v3.converted == 0],\n",
    "                                       train_size = 0.99)\n",
    "\n",
    "train_set_1, test_set_1 = train_test_split(eureka_df_v3[eureka_df_v3.converted == 1],\n",
    "                                       train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.concat([train_set_0, train_set_1])\n",
    "test_set = pd.concat([test_set_0, test_set_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.converted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.converted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resamping to create balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample, shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_1 = resample(train_set[train_set.converted == 1],\n",
    "                             replace = True,\n",
    "                             n_samples=50000)\n",
    "\n",
    "train_label_0 = resample(train_set[train_set.converted == 0],\n",
    "                             replace = False,\n",
    "                             n_samples=50000)                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine majority class with upsampled minority class\n",
    "train_set_resampled = pd.concat([train_label_1, train_label_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_resampled = shuffle(train_set_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "\n",
    "### Buidling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_v1 = DecisionTreeClassifier(max_depth=8, \n",
    "                                 criterion = 'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_v1.fit(train_set_resampled[X_features], \n",
    "            train_set_resampled['converted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tree_pred = tree_v1.predict(test_set[X_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf = confusion_matrix(test_set['converted'], y_tree_pred, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.heatmap(cm_rf,\n",
    "           fmt='.0f',\n",
    "           annot = True,\n",
    "           xticklabels = ['Converted', 'Not Converted'],\n",
    "           yticklabels = ['Converted', 'Not Converted'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_pred_prob = tree_v1.predict_proba(test_set[X_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(test_set['converted'], y_rf_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(tree_v1, test_set[X_features], \n",
    "               test_set['converted']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame({'feature': X_features,\n",
    "                            'importance': np.round(tree_v1.feature_importances_, 3) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.sort_values('importance', \n",
    "                                      ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "sn.barplot(y = 'feature', \n",
    "           x = 'importance', \n",
    "           data = features_df[0:50]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['cumsum'] = features_df.importance.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cumsum_df = features_df.sort_values('cumsum', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cumsum_df = imp_cumsum_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cumsum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model\n",
    "\n",
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 100,\n",
    "                                max_depth=8,\n",
    "                                max_features=0.3,\n",
    "                                max_samples=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(train_set_resampled[X_features], \n",
    "           train_set_resampled['converted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_pred = rf_clf.predict(test_set[X_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf = confusion_matrix(test_set['converted'], y_rf_pred, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.heatmap(cm_rf,\n",
    "           fmt='.0f',\n",
    "           annot = True,\n",
    "           xticklabels = ['Converted', 'Not Converted'],\n",
    "           yticklabels = ['Converted', 'Not Converted'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_pred_prob = rf_clf.predict_proba(test_set[X_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(test_set['converted'], y_rf_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "precision_score(test_set['converted'], y_rf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame({'feature': X_features,\n",
    "                            'importance': np.round( rf_clf.feature_importances_, 3) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.sort_values('importance', \n",
    "                                      ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "sn.barplot(y = 'feature', \n",
    "           x = 'importance', \n",
    "           data = features_df[0:50]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['cumsum'] = features_df.importance.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cumsum_df = features_df.sort_values('cumsum', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cumsum_df = imp_cumsum_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cumsum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift Chart and Gain Chart \n",
    "\n",
    "### By Decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predict_prob_df = pd.DataFrame( { 'actual': test_set['converted'], \n",
    "                                         'prob' : y_rf_pred_prob[:,1] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predict_prob_df = sorted_predict_prob_df.sort_values('prob', \n",
    "                                                            ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predict_prob_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_decile = int( len( sorted_predict_prob_df ) / 10 )\n",
    "print( \"Number of observations per decile: \", num_per_decile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_predict_prob_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deciles( df ):\n",
    "    df['decile'] = 1\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for each_d in range( 0, 10 ):\n",
    "        df.iloc[idx:idx+num_per_decile, df.columns.get_loc('decile')] = each_d \n",
    "        idx += num_per_decile\n",
    "\n",
    "    df['decile'] = df['decile'] + 1    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles_predict_df = get_deciles( sorted_predict_prob_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles_predict_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df = pd.DataFrame( \n",
    "    deciles_predict_df.groupby( \n",
    "            'decile')['actual'].sum() ).reset_index()\n",
    "gain_lift_df.columns = ['decile', 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df['gain_percentage'] = (100 * \n",
    "            gain_lift_df.gain.cumsum()/gain_lift_df.gain.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (8,4))\n",
    "plt.plot( gain_lift_df['decile'], \n",
    "         gain_lift_df['gain_percentage'], '-' )\n",
    "\n",
    "plt.title(\"Gain Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df['lift'] = ( gain_lift_df.gain_percentage \n",
    "                        / ( gain_lift_df.decile * 10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df['lift'] = ( gain_lift_df.gain_percentage \n",
    "                        / ( gain_lift_df.decile ) )\n",
    "\n",
    "gain_lift_df\n",
    "\n",
    "plt.figure( figsize = (8,4))\n",
    "plt.plot( gain_lift_df['decile'], gain_lift_df['lift'], '-' )\n",
    "plt.title(\"Lift Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predict_prob_df = pd.DataFrame( { 'actual': test_set['converted'], \n",
    "                                         'prob' : y_rf_pred_prob[:,1] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predict_prob_df = sorted_predict_prob_df.sort_values('prob', \n",
    "                                                            ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_percentile = int( len( sorted_predict_prob_df ) / 100 )\n",
    "print( \"Number of observations per percentile: \", num_per_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentiles( df ):\n",
    "    df['percentile'] = 1\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for each_d in range( 0, 100 ):\n",
    "        df.iloc[idx:idx+num_per_decile, df.columns.get_loc('percentile')] = each_d \n",
    "        idx += num_per_percentile\n",
    "\n",
    "    df['percentile'] = df['percentile'] + 1    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_predict_df = get_percentiles( sorted_predict_prob_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_predict_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df = pd.DataFrame( \n",
    "    percentile_predict_df.groupby( \n",
    "            'percentile')['actual'].sum() ).reset_index()\n",
    "gain_lift_df.columns = ['percentile', 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df['gain_percentage'] = (100 * \n",
    "            gain_lift_df.gain.cumsum()/gain_lift_df.gain.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (8,4))\n",
    "plt.plot( gain_lift_df['percentile'], \n",
    "         gain_lift_df['gain_percentage'], '-' )\n",
    "\n",
    "plt.title(\"Gain Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df['lift'] = ( gain_lift_df.gain_percentage \n",
    "                        / ( gain_lift_df.percentile ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_lift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = (8,4))\n",
    "plt.plot( gain_lift_df['percentile'], gain_lift_df['lift'], '-' )\n",
    "plt.title(\"Lift Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
