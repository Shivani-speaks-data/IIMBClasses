{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB9078CXtyRS"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m3UqfOZVtyRU"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFTNSWYUtyRV"
      },
      "source": [
        "## Load images from directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1JFZDEqRcReAjJiqCxz-W4707ipDEFe6i -O trainset.zip\n",
        "!unzip -q trainset.zip -d trainset/"
      ],
      "metadata": {
        "id": "51AefXwauQ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7SSXWd1KtyRV"
      },
      "outputs": [],
      "source": [
        "train_image_dir = '/content/trainset/MultiClassDataDemo/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUvEonvTtyRW"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=64,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7zVn145tyRW"
      },
      "outputs": [],
      "source": [
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DFMe6pl3tyRW"
      },
      "outputs": [],
      "source": [
        "image_shape = train_generator.image_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bmO1CYxtyRX"
      },
      "outputs": [],
      "source": [
        "train_generator.n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxZVNFKYtyRX"
      },
      "source": [
        "## Read the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wljilupFtyRX"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = next(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH7oLjantyRX"
      },
      "outputs": [],
      "source": [
        "x_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bNFufcTtyRY"
      },
      "outputs": [],
      "source": [
        "y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35Aql-natyRY"
      },
      "outputs": [],
      "source": [
        "plt.imshow( x_batch[0] );\n",
        "plt.grid(False)    \n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XY4sA49tyRY"
      },
      "source": [
        "### Show random images from a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d2FHhmX5tyRY"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "\n",
        "def show_random_images( x_batch_images, y_batch_images ):\n",
        "\n",
        "    all_indexes = list(range(len(x_batch_images)))\n",
        "    random_indexes = random.sample( all_indexes, 8 )\n",
        "\n",
        "    plt.figure( figsize=(16, 8))\n",
        "    \n",
        "    k = 1    \n",
        "    for i in random_indexes:\n",
        "        plt.subplot(2, 4, k);\n",
        "        plt.grid(False)\n",
        "        plt.imshow(x_batch_images[i])\n",
        "        plt.title(y_batch_images[i])\n",
        "        k = k + 1\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwa7afwVtyRZ"
      },
      "outputs": [],
      "source": [
        "show_random_images( x_batch, y_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFLgAysFtyRa"
      },
      "source": [
        "## Image Rotations\n",
        "\n",
        "The training dataset contains images, which are mostly aligned vertically. But while predicting users may take leaf images from many different angles. So we augment our training samples by randomly rotating images from 0 to 90 degrees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B6pnwOFtyRa"
      },
      "outputs": [],
      "source": [
        "rotate_train_datagen = ImageDataGenerator(rotation_range=90, \n",
        "                                          rescale=1./256)\n",
        "\n",
        "rotate_train_generator = rotate_train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kGchwNB_tyRb"
      },
      "outputs": [],
      "source": [
        "x_rotate_batch, y_batch = next(rotate_train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_RTOHH_tyRb"
      },
      "outputs": [],
      "source": [
        "x_rotate_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-gsSa_ftyRb"
      },
      "outputs": [],
      "source": [
        "show_random_images(x_rotate_batch, y_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1jma8hYtyRb"
      },
      "source": [
        "## Zooming In and Out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umfdu76DtyRb"
      },
      "outputs": [],
      "source": [
        "zoom_train_datagen = ImageDataGenerator(zoom_range=0.4, \n",
        "                                        rescale=1./256)\n",
        "\n",
        "zoom_train_generator = zoom_train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYevEeIntyRc"
      },
      "outputs": [],
      "source": [
        "x_zoom_batch, y_batch = next(zoom_train_generator)\n",
        "show_random_images(x_zoom_batch, y_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9PEPbSityRc"
      },
      "source": [
        "## Shifting Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itUE_33PtyRc"
      },
      "outputs": [],
      "source": [
        "shift_train_datagen = ImageDataGenerator(rescale=1./256,\n",
        "                                        width_shift_range=0.2,\n",
        "                                        height_shift_range=0.2)\n",
        "\n",
        "shift_train_generator = shift_train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qql_P12btyRc"
      },
      "outputs": [],
      "source": [
        "x_shift_batch, y_batch = next(shift_train_generator)\n",
        "show_random_images(x_shift_batch, y_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHOhLQCFtyRc"
      },
      "source": [
        "## Combining multiple data augmentation techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hw9jO7rDtyRc"
      },
      "outputs": [],
      "source": [
        "augmented_train_datagen = ImageDataGenerator(rescale=1./256,\n",
        "                                         rotation_range=90,\n",
        "                                         width_shift_range=0.2,\n",
        "                                         height_shift_range=0.2,\n",
        "                                         zoom_range=0.4)\n",
        "\n",
        "augmented_train_generator = augmented_train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=128,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZI8QdVgtyRd"
      },
      "outputs": [],
      "source": [
        "x_augmented_batch, y_batch = next(augmented_train_generator)\n",
        "show_random_images(x_augmented_batch, y_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sez48niDtyRd"
      },
      "source": [
        "## Building a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xRYcwv1qtyRd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Input, ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eTtACrxktyRd"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3,3), strides=1, padding='same', input_shape=image_shape))\n",
        "model.add(ReLU())\n",
        "                            \n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='same', input_shape=image_shape))\n",
        "model.add(ReLU())\n",
        "                            \n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Conv2D(filters=64, \n",
        "                 kernel_size=(3,3), \n",
        "                 strides=1, \n",
        "                 padding='same', \n",
        "                 input_shape=image_shape))\n",
        "model.add(ReLU())\n",
        "                            \n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(Flatten())\n",
        "    \n",
        "model.add(Dense(256))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(ReLU())\n",
        "\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k0jowyqktyRd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ic3Uv6RqtyRe"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7hPwNfPstyRe"
      },
      "outputs": [],
      "source": [
        "callbacks_list = [ReduceLROnPlateau(monitor='val_loss',\n",
        "                                    factor=0.1, \n",
        "                                    patience=2),\n",
        "                 EarlyStopping(monitor='val_loss',\n",
        "                               patience=2),\n",
        "                 ModelCheckpoint(filepath='my_model.h5',\n",
        "                                 monitor='val_loss',\n",
        "                                 save_best_only=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_mkvFkBtyRe"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit_generator(augmented_train_generator,\n",
        "                              steps_per_epoch=20,\n",
        "                              epochs=5,\n",
        "                              callbacks=callbacks_list,\n",
        "                              validation_data=augmented_train_generator,\n",
        "                              validation_steps=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hJgwcaBBtyRe"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump( history.history, open('history_aug_nozca.pkl', 'wb') )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2_JzMIC1tyRf"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "\n",
        "def plot_train_val_accuracy(hist):\n",
        "    plt.plot(hist['acc'])\n",
        "    plt.plot(hist['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "coHgm51StyRf"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "\n",
        "def plot_train_val_loss(hist):\n",
        "    plt.plot(hist['loss'])\n",
        "    plt.plot(hist['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6NeAihWtyRf"
      },
      "outputs": [],
      "source": [
        "plot_train_val_accuracy( history.history )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwc1_h_ctyRf"
      },
      "outputs": [],
      "source": [
        "history.history.values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0txIhE4tyRZ"
      },
      "source": [
        "## ZCA Whiteing\n",
        "\n",
        "A whitening transform minimizes the redundancy in the matrix of pixel images. Initutively, it highlights the pixels with high variance across images.  \n",
        "\n",
        "Image whitening uses the same dimesional reduction technique as Principal Component Analysis (PCA), alternative called ZCA. However the transformed image retains the same dimensions of original image.\n",
        "\n",
        "You can perform a ZCA whitening transform by setting the zca_whitening argument to True in *ImageDataGenerator*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6-y7s2VtyRZ"
      },
      "outputs": [],
      "source": [
        "zca_train_datagen = ImageDataGenerator(zca_whitening=True)\n",
        "\n",
        "zca_train_generator = zca_train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=8,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j0j9xtttyRZ"
      },
      "outputs": [],
      "source": [
        "x_zca_batch, y_batch = next(zca_train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lof62_qhtyRa"
      },
      "outputs": [],
      "source": [
        "x_zca_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13xrmRyYtyRa"
      },
      "outputs": [],
      "source": [
        "show_random_images( x_zca_batch, y_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtMtxLH1tyRf"
      },
      "source": [
        "## Combined Data Augmentation + whitening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yTCAEO5tyRf"
      },
      "outputs": [],
      "source": [
        "augmented_zca_train_datagen = ImageDataGenerator(rotation_range=90,\n",
        "                                         width_shift_range=0.2,\n",
        "                                         height_shift_range=0.2,\n",
        "                                         zoom_range=0.4,\n",
        "                                         zca_whitening=True)\n",
        "\n",
        "augmented_zca_train_generator = augmented_zca_train_datagen.flow_from_directory(train_image_dir,\n",
        "                                                    target_size=(256, 256),\n",
        "                                                    batch_size=128,\n",
        "                                                    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hh5prEntyRg"
      },
      "outputs": [],
      "source": [
        "x_augmented_zca_batch, y_batch = next(augmented_zca_train_generator)\n",
        "show_random_images(x_augmented_zca_batch, y_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OOVrMb-QtyRg"
      },
      "outputs": [],
      "source": [
        "K.clear_session()  # clear default graph\n",
        "\n",
        "model_zca = Sequential()\n",
        "model_zca.add(Conv2D(filters=16, kernel_size=(3,3), strides=1, padding='same', input_shape=image_shape))\n",
        "model_zca.add(LeakyReLU(0.1))\n",
        "                            \n",
        "model_zca.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model_zca.add(Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='same', input_shape=image_shape))\n",
        "model_zca.add(LeakyReLU(0.1))\n",
        "                            \n",
        "model_zca.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model_zca.add(Conv2D(filters=64, kernel_size=(3,3), strides=1, padding='same', input_shape=image_shape))\n",
        "model_zca.add(LeakyReLU(0.1))\n",
        "                            \n",
        "model_zca.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model_zca.add(Flatten())\n",
        "    \n",
        "model_zca.add(Dense(256))\n",
        "model_zca.add(LeakyReLU(0.1))\n",
        "model_zca.add(Dropout(0.5))\n",
        "\n",
        "model_zca.add(Dense(64))\n",
        "model_zca.add(LeakyReLU(0.1))\n",
        "model_zca.add(Dropout(0.5))\n",
        "\n",
        "model_zca.add(Dense(10))\n",
        "model_zca.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zLjtdj0ntyRg"
      },
      "outputs": [],
      "source": [
        "model_zca.compile(optimizer='adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U9hrHzr3tyRg"
      },
      "outputs": [],
      "source": [
        "callbacks_list = [ReduceLROnPlateau(monitor='val_loss',\n",
        "                                    factor=0.1, \n",
        "                                    patience=2),\n",
        "                 EarlyStopping(monitor='val_loss',\n",
        "                               patience=2),\n",
        "                 ModelCheckpoint(filepath='my_model.h5',\n",
        "                                 monitor='val_loss',\n",
        "                                 save_best_only=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw_SsKvxtyRg"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "history_zca = model_zca.fit_generator(augmented_train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=50,\n",
        "                              callbacks=callbacks_list,\n",
        "                              validation_data=augmented_train_generator,\n",
        "                              validation_steps=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TVSSDJCBtyRh"
      },
      "outputs": [],
      "source": [
        "pickle.dump( history.history, open('history_aug_zca.pkl', 'wb') )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zScNy_vutyRh"
      },
      "outputs": [],
      "source": [
        "plot_train_val_accuracy(history_zca.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HDAJ-SzstyRh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}